
import React, { useEffect } from 'react';
import KioskHeader from '@/components/KioskHeader';
import KioskFooter from '@/components/KioskFooter';
import MainKioskInterface from '@/components/MainKioskInterface';
import AppointmentBookingModal from '@/components/AppointmentBookingModal';
import { useKioskState } from '@/hooks/useKioskState';
import { useDialogflowCXService } from '@/hooks/useDialogflowCXService';
import { useGoogleCloudServices } from '@/hooks/useGoogleCloudServices';
import { useAutoLanguageDetection } from '@/hooks/useAutoLanguageDetection';
import { useToast } from '@/hooks/use-toast';
import { hospitalDataService } from '@/services/hospitalDataService';

const EnhancedKiosk = () => {
  const { toast } = useToast();
  const { state, updateState } = useKioskState();
  const { processWithDialogflowCX } = useDialogflowCXService();
  const { textToSpeech, playAudio } = useGoogleCloudServices();
  const { startListening: detectLanguage } = useAutoLanguageDetection();

  // Welcome message on load
  useEffect(() => {
    const welcomeMessage = {
      responseText: "ðŸŒŸ Welcome to MediCare Smart Kiosk! Your intelligent healthcare assistant powered by advanced AI and voice recognition technology. I can help you with hospital directions, appointment bookings, department information, and much more - all in multiple languages including English, Hindi, Tamil, Malayalam, Telugu, and more!",
      intent: 'welcome',
      entities: {},
      confidence: 1.0,
      responseTime: 0,
      responseData: { 
        type: 'welcome',
        features: ['voice-recognition', 'face-detection', 'multi-language', 'navigation', 'appointments']
      },
      success: true
    };
    updateState({ currentResponse: welcomeMessage });
  }, [updateState]);

  const handleAutoGreeting = async () => {
    console.log('ðŸŽ¯ Auto-greeting triggered by face detection');
    updateState({ isAutoDetecting: true });
    
    const enhancedGreetings = {
      'en-US': "Hello and welcome to MediCare Hospital! I'm your intelligent AI assistant, here to help you with directions, appointments, and hospital information. I can understand and respond in multiple languages. How may I assist you today?",
      'ta-IN': "à®µà®£à®•à¯à®•à®®à¯! à®®à¯†à®Ÿà®¿à®•à¯‡à®°à¯ à®®à®°à¯à®¤à¯à®¤à¯à®µà®®à®©à¯ˆà®•à¯à®•à¯ à®µà®°à®µà¯‡à®±à¯à®•à®¿à®±à¯‹à®®à¯! à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯ à®ªà¯à®¤à¯à®¤à®¿à®šà®¾à®²à®¿ AI à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à¯. à®¤à®¿à®šà¯ˆà®•à®³à¯, à®…à®ªà¯à®ªà®¾à®¯à®¿à®£à¯à®Ÿà¯à®®à¯†à®©à¯à®Ÿà¯à®•à®³à¯, à®®à®±à¯à®±à¯à®®à¯ à®®à®°à¯à®¤à¯à®¤à¯à®µà®®à®©à¯ˆ à®¤à®•à®µà®²à¯à®•à®³à¯à®•à¯à®•à¯ à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯. à®ªà®² à®®à¯Šà®´à®¿à®•à®³à®¿à®²à¯ à®ªà¯‡à®šà®¿ à®ªà¯à®°à®¿à®¨à¯à®¤à¯à®•à¯Šà®³à¯à®³ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯. à®‡à®©à¯à®±à¯ à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®Žà®ªà¯à®ªà®Ÿà®¿ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯?",
      'ml-IN': "à´¨à´®à´¸àµà´•à´¾à´°à´‚! à´®àµ†à´¡à´¿à´•àµ†à´¯àµ¼ à´¹àµ‹à´¸àµà´ªà´¿à´±àµà´±à´²à´¿à´²àµ‡à´•àµà´•àµ à´¸àµà´µà´¾à´—à´¤à´‚! à´žà´¾àµ» à´¨à´¿à´™àµà´™à´³àµà´Ÿàµ† à´¬àµà´¦àµà´§à´¿à´®à´¾à´¨à´¾à´¯ AI à´…à´¸à´¿à´¸àµà´±àµà´±à´¨àµà´±à´¾à´£àµ. à´¦à´¿à´¶à´•àµ¾, à´…à´ªàµà´ªàµ‹à´¯à´¿à´¨àµà´±àµà´®àµ†à´¨àµà´±àµà´•àµ¾, à´†à´¶àµà´ªà´¤àµà´°à´¿ à´µà´¿à´µà´°à´™àµà´™àµ¾ à´Žà´¨àµà´¨à´¿à´µà´¯à´¿àµ½ à´¸à´¹à´¾à´¯à´¿à´•àµà´•à´¾àµ» à´žà´¾àµ» à´‡à´µà´¿à´Ÿàµ†à´¯àµà´£àµà´Ÿàµ. à´ªà´² à´­à´¾à´·à´•à´³à´¿à´²àµà´‚ à´¸à´‚à´¸à´¾à´°à´¿à´•àµà´•à´¾à´¨àµà´‚ à´®à´¨à´¸àµà´¸à´¿à´²à´¾à´•àµà´•à´¾à´¨àµà´‚ à´•à´´à´¿à´¯àµà´‚à¥¤ à´‡à´¨àµà´¨àµ à´Žà´¨à´¿à´•àµà´•àµ à´¨à´¿à´™àµà´™à´³àµ† à´Žà´™àµà´™à´¨àµ† à´¸à´¹à´¾à´¯à´¿à´•àµà´•à´¾à´‚?",
      'hi-IN': "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥‡à¤¡à¤¿à¤•à¥‡à¤¯à¤° à¤…à¤¸à¥à¤ªà¤¤à¤¾à¤² à¤®à¥‡à¤‚ à¤†à¤ªà¤•à¤¾ à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤¹à¥ˆ! à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¤¾ à¤¬à¥à¤¦à¥à¤§à¤¿à¤®à¤¾à¤¨ AI à¤¸à¤¹à¤¾à¤¯à¤• à¤¹à¥‚à¤‚à¥¤ à¤¦à¤¿à¤¶à¤¾-à¤¨à¤¿à¤°à¥à¤¦à¥‡à¤¶, à¤…à¤ªà¥‰à¤‡à¤‚à¤Ÿà¤®à¥‡à¤‚à¤Ÿ, à¤”à¤° à¤…à¤¸à¥à¤ªà¤¤à¤¾à¤² à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤•à¥‡ à¤²à¤¿à¤ à¤®à¥ˆà¤‚ à¤¯à¤¹à¤¾à¤‚ à¤¹à¥‚à¤‚à¥¤ à¤•à¤ˆ à¤­à¤¾à¤·à¤¾à¤“à¤‚ à¤®à¥‡à¤‚ à¤¬à¤¾à¤¤ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤”à¤° à¤¸à¤®à¤ à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤ à¤†à¤œ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚?",
      'te-IN': "à°¨à°®à°¸à±à°•à°¾à°°à°‚! à°®à±†à°¡à°¿à°•à±‡à°°à± à°¹à°¾à°¸à±à°ªà°¿à°Ÿà°²à±â€Œà°•à± à°¸à±à°µà°¾à°—à°¤à°‚! à°¨à±‡à°¨à± à°®à±€ à°¤à±†à°²à°¿à°µà±ˆà°¨ AI à°¸à°¹à°¾à°¯à°•à±à°¡à°¨à±à¥¤ à°¦à°¿à°¶à°²à±, à°…à°ªà°¾à°¯à°¿à°‚à°Ÿà±â€Œà°®à±†à°‚à°Ÿà±à°²à±, à°®à°°à°¿à°¯à± à°¹à°¾à°¸à±à°ªà°¿à°Ÿà°²à± à°¸à°®à°¾à°šà°¾à°°à°‚ à°•à±‹à°¸à°‚ à°¨à±‡à°¨à± à°‡à°•à±à°•à°¡ à°‰à°¨à±à°¨à°¾à°¨à±à¥¤ à°…à°¨à±‡à°• à°­à°¾à°·à°²à°²à±‹ à°®à°¾à°Ÿà±à°²à°¾à°¡à°—à°²à°¨à± à°®à°°à°¿à°¯à± à°…à°°à±à°¥à°‚ à°šà±‡à°¸à±à°•à±‹à°—à°²à°¨à±à¥¤ à°ˆà°°à±‹à°œà± à°¨à±‡à°¨à± à°®à±€à°•à± à°Žà°²à°¾ à°¸à°¹à°¾à°¯à°‚ à°šà±‡à°¯à°—à°²à°¨à±?"
    };

    try {
      console.log('ðŸ”Š Playing enhanced greeting with visual feedback');
      
      // Enhanced toast notification
      toast({
        title: "ðŸ‘‹ Welcome! Face Detected",
        description: "AI Assistant is now active and ready to help you. Please speak clearly.",
        duration: 8000,
      });

      const greeting = enhancedGreetings[state.selectedLanguage] || enhancedGreetings['en-US'];
      
      const greetingResponse = {
        responseText: greeting,
        intent: 'auto-greeting',
        entities: {},
        confidence: 1.0,
        responseTime: 0,
        responseData: { 
          type: 'auto-greeting', 
          triggered: 'face-detection',
          language: state.selectedLanguage,
          timestamp: new Date().toISOString()
        },
        success: true
      };

      updateState({ 
        currentResponse: greetingResponse,
        conversationHistory: [...state.conversationHistory, {
          type: 'assistant',
          content: greeting,
          timestamp: new Date(),
          intent: 'auto-greeting',
          confidence: 1.0,
          trigger: 'face-detection',
          language: state.selectedLanguage
        }],
        lastGreetingTime: Date.now()
      });

      console.log('ðŸŽµ Starting TTS for greeting...');
      const ttsResult = await textToSpeech(greeting, state.selectedLanguage);
      
      if (ttsResult.success && ttsResult.audioContent) {
        console.log('âœ… Playing greeting audio...');
        await playAudio(ttsResult.audioContent);
        console.log('ðŸŽ‰ Greeting audio completed successfully');
        
        // Success feedback
        toast({
          title: "ðŸŽ¤ Voice Recognition Active",
          description: "You can now speak naturally. I'll detect your language automatically.",
          duration: 5000,
        });
        
        // Start listening for user response after greeting
        setTimeout(async () => {
          try {
            console.log('ðŸŽ§ Starting automatic language detection...');
            updateState({ isListening: true });
            
            const languageResult = await detectLanguage();
            if (languageResult && languageResult.transcript && languageResult.transcript.trim()) {
              console.log('ðŸ—£ï¸ User responded:', languageResult);
              
              // Update language if different
              if (languageResult.detectedLanguage !== state.selectedLanguage) {
                updateState({ selectedLanguage: languageResult.detectedLanguage });
                toast({
                  title: "ðŸŒ Language Detected",
                  description: `Switched to ${languageResult.detectedLanguage}`,
                  duration: 4000,
                });
              }
              
              await handleVoiceInput(languageResult.transcript, languageResult.confidence, languageResult.detectedLanguage);
            } else {
              console.log('ðŸ‘‚ No immediate response - user can speak anytime');
              toast({
                title: "ðŸ‘‚ Ready to Listen",
                description: "No immediate response detected. Feel free to speak anytime!",
                duration: 4000,
              });
            }
          } catch (error) {
            console.log('ðŸ¤« No speech detected during auto-listen phase (normal):', error);
          } finally {
            updateState({ isAutoDetecting: false, isListening: false });
          }
        }, 3000); // Give user time to process the greeting
        
      } else {
        console.error('âŒ TTS failed:', ttsResult.error);
        toast({
          title: "âš ï¸ Audio Issue",
          description: "Face detected but audio playback failed. You can still use voice commands.",
          variant: "destructive",
        });
        updateState({ isAutoDetecting: false });
      }

    } catch (error) {
      console.error('ðŸ’¥ Auto-greeting error:', error);
      updateState({ isAutoDetecting: false });
      
      toast({
        title: "âš ï¸ System Error",
        description: "Face detected but greeting system failed. Please use voice commands manually.",
        variant: "destructive",
      });
    }
  };

  const handleVoiceInput = async (transcript: string, confidence: number, detectedLanguage: string) => {
    console.log('ðŸŽ¤ Processing voice input:', { transcript, confidence, detectedLanguage });
    
    // Auto-switch language if detected differently
    if (detectedLanguage !== state.selectedLanguage) {
      updateState({ selectedLanguage: detectedLanguage });
      console.log('ðŸŒ Language auto-switched to:', detectedLanguage);
      
      toast({
        title: "ðŸŒ Language Auto-Detected",
        description: `Now responding in ${detectedLanguage}`,
        duration: 3000,
      });
    }
    
    // Store session data
    await hospitalDataService.createOrUpdateKioskSession(state.sessionId, detectedLanguage);
    
    const newHistory = [...state.conversationHistory, {
      type: 'user',
      content: transcript,
      timestamp: new Date(),
      language: detectedLanguage,
      confidence
    }];

    // Process with Dialogflow CX
    console.log('ðŸ¤– Processing with Dialogflow CX...');
    const dialogflowResponse = await processWithDialogflowCX(transcript, state.sessionId, detectedLanguage);
    
    // Handle appointment intents
    if (dialogflowResponse.intent?.toLowerCase().includes('appointment')) {
      updateState({ showAppointmentModal: true });
    }
    
    // Handle department selection
    let selectedDepartment = state.selectedDepartment;
    if (dialogflowResponse.responseData?.department) {
      selectedDepartment = dialogflowResponse.responseData.department;
    }
    
    updateState({
      currentResponse: dialogflowResponse,
      selectedDepartment,
      conversationHistory: [...newHistory, {
        type: 'assistant',
        content: dialogflowResponse.responseText,
        timestamp: new Date(),
        intent: dialogflowResponse.intent,
        confidence: dialogflowResponse.confidence,
        language: detectedLanguage
      }]
    });

    // Auto-play response
    try {
      console.log('ðŸ”Š Playing response audio...');
      const ttsResult = await textToSpeech(dialogflowResponse.responseText, detectedLanguage);
      if (ttsResult.success && ttsResult.audioContent) {
        await playAudio(ttsResult.audioContent);
        console.log('âœ… Response audio played successfully');
      } else {
        console.error('âŒ Response audio failed:', ttsResult.error);
      }
    } catch (error) {
      console.error('ðŸ’¥ Response audio playback failed:', error);
    }

    // Success feedback
    toast({
      title: "ðŸŽ¤ Voice Processed Successfully",
      description: `Language: ${detectedLanguage} (${Math.round(confidence * 100)}% confidence)`,
      duration: 3000,
    });
  };

  const handleFaceDetection = (detected: boolean, count: number) => {
    updateState({ facesDetected: detected, faceCount: count });
    
    if (detected) {
      console.log(`ðŸ‘¥ Face detection updated: ${count} face(s) detected`);
    }
  };

  const handleQuickAction = async (query: string) => {
    console.log('âš¡ Quick action triggered:', query);
    await handleVoiceInput(query, 1.0, state.selectedLanguage);
  };

  const handleDepartmentSelect = (department: string) => {
    updateState({ selectedDepartment: department });
    handleQuickAction(`Tell me about ${department} department and show me directions`);
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 via-white to-green-50 flex flex-col touch-manipulation selection:bg-blue-200">
      <KioskHeader
        facesDetected={state.facesDetected}
        faceCount={state.faceCount}
        selectedLanguage={state.selectedLanguage}
        autoInteractionEnabled={state.autoInteractionEnabled}
        onLanguageChange={(lang) => updateState({ selectedLanguage: lang })}
        onToggleAutoInteraction={() => updateState({ 
          autoInteractionEnabled: !state.autoInteractionEnabled 
        })}
      />

      <MainKioskInterface
        state={state}
        isListening={state.isListening}
        onVoiceData={handleVoiceInput}
        onListeningChange={(listening) => updateState({ isListening: listening })}
        onFaceDetected={handleFaceDetection}
        onQuickAction={handleQuickAction}
        onDepartmentSelect={handleDepartmentSelect}
        onShowAppointmentModal={() => updateState({ showAppointmentModal: true })}
        onAutoGreetingTriggered={handleAutoGreeting}
      />

      <KioskFooter />

      <AppointmentBookingModal
        isOpen={state.showAppointmentModal}
        onClose={() => updateState({ showAppointmentModal: false })}
        department={state.selectedDepartment}
      />
    </div>
  );
};

export default EnhancedKiosk;
