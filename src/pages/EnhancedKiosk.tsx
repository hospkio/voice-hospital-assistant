import React, { useEffect, useRef } from 'react';
import { useKioskState } from '@/hooks/useKioskState';
import { useGoogleCloudServices } from '@/hooks/useGoogleCloudServices';
import KioskHeader from '@/components/KioskHeader';
import MainKioskInterface from '@/components/MainKioskInterface';
import KioskFooter from '@/components/KioskFooter';
import AppointmentBookingModal from '@/components/AppointmentBookingModal';
import { toast } from 'sonner';
import SecurityHelpers from '@/utils/securityHelpers';

// Add type declaration for webkit speech recognition
declare global {
  interface Window {
    webkitSpeechRecognition: any;
  }
}

const EnhancedKiosk: React.FC = () => {
  const { state, updateState, clearSensitiveData, validateState } = useKioskState();
  const { speechToText, textToSpeech, playAudio, processWithDialogflowCX } = useGoogleCloudServices();
  const recognitionRef = useRef<any>(null);
  const processingRef = useRef(false);

  useEffect(() => {
    if (state.isListening && !recognitionRef.current) {
      console.log('üé§ Initializing speech recognition...');
      initializeSpeechRecognition(state.selectedLanguage);
    } else if (!state.isListening && recognitionRef.current) {
      console.log('üõë Stopping speech recognition...');
      stopSpeechRecognition();
    }
  }, [state.isListening, state.selectedLanguage]);

  useEffect(() => {
    if (recognitionRef.current) {
      console.log('üåê Updating speech recognition language to:', state.selectedLanguage);
      recognitionRef.current.lang = state.selectedLanguage;
    }
  }, [state.selectedLanguage]);

  const initializeSpeechRecognition = (language: string) => {
    if ('webkitSpeechRecognition' in window) {
      recognitionRef.current = new window.webkitSpeechRecognition();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = language;
      
      recognitionRef.current.onstart = () => {
        console.log('‚è∫Ô∏è Speech recognition started');
      };
      
      recognitionRef.current.onerror = (event: any) => {
        console.error('‚ùå Speech recognition error:', event.error);
        toast.error(`Speech recognition error: ${event.error}`);
      };
      
      recognitionRef.current.onend = () => {
        console.log('‚èπÔ∏è Speech recognition ended');
        if (state.isListening) {
          console.log('üîÑ Restarting speech recognition...');
          recognitionRef.current.start();
        }
      };
      
      recognitionRef.current.onresult = async (event: any) => {
        const transcript = Array.from(event.results)
          .map((result: any) => result[0])
          .map((result: any) => result.transcript)
          .join('');
          
        const confidence = event.results[event.results.length - 1][0].confidence;
        
        console.log('üëÇ Interim transcript:', transcript, 'Confidence:', confidence);
        
        // For language detection, we'll use the current language as detected language
        // since we can't easily detect language from transcript alone
        let detectedLanguage = language;
        
        handleVoiceData(transcript, confidence, detectedLanguage);
      };
      
      recognitionRef.current.start();
    } else {
      console.warn('Speech recognition not supported in this browser.');
      toast.error('Speech recognition not supported in this browser.');
      updateState({ isListening: false });
    }
  };

  const stopSpeechRecognition = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current.onstart = null;
      recognitionRef.current.onerror = null;
      recognitionRef.current.onend = null;
      recognitionRef.current.onresult = null;
      recognitionRef.current = null;
    }
  };

  // Enhanced language change handler
  const handleLanguageChange = (language: string) => {
    console.log('üåê Language changed to:', language);
    updateState({ selectedLanguage: language });
    
    // Log security event for language changes
    SecurityHelpers.logSecurityEvent('Language changed', { 
      newLanguage: language,
      sessionId: state.sessionId 
    });
    
    toast.success(`Language changed to ${language}`);
  };

  // Enhanced voice data handler with multi-language support
  const handleVoiceData = async (transcript: string, confidence: number, detectedLanguage: string) => {
    if (processingRef.current) {
      console.log('üîÑ Already processing, skipping...');
      return;
    }
    
    processingRef.current = true;
    console.log('üé§ Voice data received:', { transcript, confidence, detectedLanguage });
    
    try {
      // Validate transcript
      if (!transcript?.trim()) {
        console.log('‚ö†Ô∏è Empty transcript received');
        return;
      }
      
      // Basic security validation - simple sanitization
      const sanitizedTranscript = transcript.replace(/[<>]/g, '').trim();
      if (!sanitizedTranscript) {
        SecurityHelpers.logSecurityEvent('Invalid voice input detected', { 
          transcript: transcript.substring(0, 100),
          sessionId: state.sessionId 
        });
        toast.error('Invalid input detected. Please try again.');
        return;
      }
      
      // Update language if detected different from current
      if (detectedLanguage && detectedLanguage !== state.selectedLanguage) {
        console.log('üîÑ Auto-updating language from', state.selectedLanguage, 'to', detectedLanguage);
        updateState({ selectedLanguage: detectedLanguage });
      }
      
      console.log('ü§ñ Processing with Dialogflow CX...');
      const response = await processWithDialogflowCX(sanitizedTranscript, state.sessionId, state.selectedLanguage);
      
      if (response.success) {
        console.log('‚úÖ Dialogflow response received:', response);
        updateState({ 
          currentResponse: {
            text: response.responseText,
            timestamp: Date.now()
          },
          conversationHistory: [...state.conversationHistory, {
            query: sanitizedTranscript,
            response: response.responseText,
            timestamp: Date.now(),
            language: detectedLanguage || state.selectedLanguage,
            confidence
          }]
        });
        
        // Generate and play audio response
        try {
          const ttsResponse = await textToSpeech(response.responseText, state.selectedLanguage);
          if (ttsResponse.success && ttsResponse.audioContent) {
            console.log('üîä Playing audio response...');
            await playAudio(ttsResponse.audioContent);
          }
        } catch (ttsError) {
          console.warn('‚ö†Ô∏è TTS failed, continuing without audio:', ttsError);
        }
      } else {
        console.error('‚ùå Dialogflow processing failed:', response);
        toast.error('Failed to process your request. Please try again.');
      }
    } catch (error) {
      console.error('‚ùå Error processing voice data:', error);
      SecurityHelpers.logSecurityEvent('Voice processing error', { 
        error: error instanceof Error ? error.message : 'Unknown error',
        sessionId: state.sessionId 
      });
      toast.error('An error occurred. Please try again.');
    } finally {
      processingRef.current = false;
    }
  };

  // Enhanced listening state handler
  const handleListeningChange = (listening: boolean) => {
    console.log('üé§ Listening state changed:', listening);
    updateState({ isListening: listening });
    
    if (listening) {
      toast.info('Listening for your voice...');
    }
  };

  // Enhanced face detection handler
  const handleFaceDetected = (detected: boolean, count: number) => {
    console.log('üë• Face detection update:', { detected, count, enabled: state.faceDetectionEnabled });
    
    // Only update state if face detection is enabled
    if (state.faceDetectionEnabled) {
      updateState({ 
        facesDetected: detected, 
        faceCount: count,
        lastGreetingTime: detected ? Date.now() : state.lastGreetingTime 
      });
      
      if (detected && count > 0) {
        console.log(`üë• ${count} face(s) detected!`);
      }
    } else {
      // Ensure state shows no faces when detection is disabled
      updateState({ facesDetected: false, faceCount: 0 });
    }
  };

  // Quick action handler
  const handleQuickAction = async (query: string) => {
    console.log('‚ö° Quick action triggered:', query);
    await handleVoiceData(query, 1.0, state.selectedLanguage);
  };

  // Department selection handler
  const handleDepartmentSelect = (department: string) => {
    console.log('üè• Department selected:', department);
    updateState({ selectedDepartment: department });
    toast.success(`Selected ${department} department`);
  };

  // Appointment modal handler
  const handleShowAppointmentModal = () => {
    console.log('üìÖ Opening appointment modal...');
    updateState({ showAppointmentModal: true });
  };

  // Enhanced auto-greeting handler - use selected language
  const handleAutoGreetingTriggered = async () => {
    if (!state.autoInteractionEnabled || !state.faceDetectionEnabled) {
      console.log('üö´ Auto-greeting disabled');
      return;
    }
    
    console.log('ü§ñ Auto-greeting triggered with language:', state.selectedLanguage);
    
    // Multi-language greetings
    const greetings = {
      'en-US': 'Hello! Welcome to our smart healthcare kiosk. I\'m here to help you with information about our hospital services, departments, and appointments. How can I assist you today?',
      'hi-IN': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§π‡•á‡§≤‡•ç‡§•‡§ï‡•á‡§Ø‡§∞ ‡§ï‡§ø‡§Ø‡•ã‡§∏‡•ç‡§ï ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§Æ‡•à‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§Ü‡§™‡§ï‡•ã ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§Ö‡§∏‡•ç‡§™‡§§‡§æ‡§≤ ‡§∏‡•á‡§µ‡§æ‡§ì‡§Ç, ‡§µ‡§ø‡§≠‡§æ‡§ó‡•ã‡§Ç ‡§î‡§∞ ‡§Ö‡§™‡•â‡§á‡§Ç‡§ü‡§Æ‡•á‡§Ç‡§ü‡•ç‡§∏ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§ú ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?',
      'ml-IN': '‡¥®‡¥Æ‡¥∏‡µç‡¥ï‡¥æ‡¥∞‡¥Ç! ‡¥û‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥∏‡µç‡¥Æ‡¥æ‡µº‡¥ü‡µç‡¥ü‡µç ‡¥π‡µÜ‡µΩ‡¥§‡µç‡¥§‡µç‡¥ï‡µÜ‡¥Ø‡µº ‡¥ï‡¥ø‡¥Ø‡µã‡¥∏‡µç‡¥ï‡¥ø‡¥≤‡µá‡¥ï‡µç‡¥ï‡µç ‡¥∏‡µç‡¥µ‡¥æ‡¥ó‡¥§‡¥Ç. ‡¥û‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥Ü‡¥∂‡µÅ‡¥™‡¥§‡µç‡¥∞‡¥ø ‡¥∏‡µá‡¥µ‡¥®‡¥ô‡µç‡¥ô‡µæ, ‡¥µ‡¥ø‡¥≠‡¥æ‡¥ó‡¥ô‡µç‡¥ô‡µæ, ‡¥Ö‡¥™‡µç‡¥™‡µã‡¥Ø‡¥ø‡¥®‡µç‡¥±‡µç‡¥Æ‡µÜ‡¥®‡µç‡¥±‡µÅ‡¥ï‡µæ ‡¥é‡¥®‡µç‡¥®‡¥ø‡¥µ‡¥Ø‡µÜ‡¥ï‡µç‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µÅ‡¥≥‡µç‡¥≥ ‡¥µ‡¥ø‡¥µ‡¥∞‡¥ô‡µç‡¥ô‡µæ ‡¥®‡µΩ‡¥ï‡¥æ‡µª ‡¥û‡¥æ‡µª ‡¥á‡¥µ‡¥ø‡¥ü‡µÜ‡¥Ø‡µÅ‡¥£‡µç‡¥ü‡µç. ‡¥á‡¥®‡µç‡¥®‡µç ‡¥û‡¥æ‡µª ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÜ ‡¥é‡¥ô‡µç‡¥ô‡¥®‡µÜ ‡¥∏‡¥π‡¥æ‡¥Ø‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡¥Ç?',
      'ta-IN': '‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç! ‡Æé‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ∏‡Øç‡ÆÆ‡Ææ‡Æ∞‡Øç‡Æü‡Øç ‡Æπ‡ØÜ‡Æ≤‡Øç‡Æ§‡Øç‡Æï‡Øá‡Æ∞‡Øç ‡Æï‡Æø‡ÆØ‡Øã‡Æ∏‡Øç‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øç‡Æï‡ØÅ ‡Æµ‡Æ∞‡Æµ‡Øá‡Æ±‡Øç‡Æï‡Æø‡Æ±‡Øã‡ÆÆ‡Øç. ‡Æé‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡ÆÆ‡Æ©‡Øà ‡Æö‡Øá‡Æµ‡Øà‡Æï‡Æ≥‡Øç, ‡Æ§‡ØÅ‡Æ±‡Øà‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ™‡Øç‡Æ™‡Ææ‡ÆØ‡Æø‡Æ©‡Øç‡Æü‡Øç‡ÆÆ‡ØÜ‡Æ©‡Øç‡Æü‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡Æ±‡Øç‡Æ±‡Æø‡ÆØ ‡Æ§‡Æï‡Æµ‡Æ≤‡Øç‡Æï‡Æ≥‡Øà ‡Æµ‡Æ¥‡Æô‡Øç‡Æï ‡Æ®‡Ææ‡Æ©‡Øç ‡Æá‡Æô‡Øç‡Æï‡Øá ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç. ‡Æá‡Æ©‡Øç‡Æ±‡ØÅ ‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æâ‡Æ§‡Æµ ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡ØÅ‡ÆÆ‡Øç?'
    };
    
    const greeting = greetings[state.selectedLanguage] || greetings['en-US'];
    
    try {
      console.log('üîä Generating TTS for auto-greeting in language:', state.selectedLanguage);
      const ttsResponse = await textToSpeech(greeting, state.selectedLanguage);
      if (ttsResponse.success && ttsResponse.audioContent) {
        console.log('üîä Playing auto-greeting audio in', state.selectedLanguage);
        await playAudio(ttsResponse.audioContent);
      }
      
      updateState({ 
        currentResponse: { 
          text: greeting, 
          audioContent: ttsResponse.audioContent,
          timestamp: Date.now()
        }
      });
    } catch (error) {
      console.error('‚ùå Auto-greeting error:', error);
    }
  };

  // Toggle auto interaction
  const handleToggleAutoInteraction = () => {
    const newState = !state.autoInteractionEnabled;
    console.log('üîÑ Toggling auto interaction:', newState);
    updateState({ autoInteractionEnabled: newState });
    toast.success(`Auto interaction ${newState ? 'enabled' : 'disabled'}`);
  };

  // Toggle face detection
  const handleToggleFaceDetection = (enabled: boolean) => {
    console.log('üîÑ Toggling face detection:', enabled);
    updateState({ faceDetectionEnabled: enabled });
    toast.success(`Face detection ${enabled ? 'enabled' : 'disabled'}`);
  };

  // Session validation effect
  useEffect(() => {
    const interval = setInterval(() => {
      if (!validateState()) {
        console.warn('‚ö†Ô∏è Invalid session state detected, clearing sensitive data');
        clearSensitiveData();
        toast.warning('Session validation failed. Starting fresh session.');
      }
    }, 300000); // Check every 5 minutes

    return () => clearInterval(interval);
  }, [validateState, clearSensitiveData]);

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 via-white to-green-50 flex flex-col">
      <KioskHeader
        facesDetected={state.facesDetected}
        faceCount={state.faceCount}
        selectedLanguage={state.selectedLanguage}
        autoInteractionEnabled={state.autoInteractionEnabled}
        faceDetectionEnabled={state.faceDetectionEnabled}
        onLanguageChange={handleLanguageChange}
        onToggleAutoInteraction={handleToggleAutoInteraction}
      />
      
      <MainKioskInterface
        state={state}
        isListening={state.isListening}
        onVoiceData={handleVoiceData}
        onListeningChange={handleListeningChange}
        onFaceDetected={handleFaceDetected}
        onQuickAction={handleQuickAction}
        onDepartmentSelect={handleDepartmentSelect}
        onShowAppointmentModal={handleShowAppointmentModal}
        onAutoGreetingTriggered={handleAutoGreetingTriggered}
        faceDetectionEnabled={state.faceDetectionEnabled}
        onFaceDetectionToggle={handleToggleFaceDetection}
        onAutoInteractionToggle={handleToggleAutoInteraction}
        onLanguageChange={handleLanguageChange}
        selectedLanguage={state.selectedLanguage}
      />
      
      <KioskFooter />
      
      {state.showAppointmentModal && (
        <AppointmentBookingModal
          isOpen={state.showAppointmentModal}
          onClose={() => updateState({ showAppointmentModal: false })}
          department={state.selectedDepartment}
        />
      )}
    </div>
  );
};

export default EnhancedKiosk;
