
import React, { useState, useEffect } from 'react';
import { useFaceDetection } from '@/hooks/useFaceDetection';
import { useGoogleCloudServices } from '@/hooks/useGoogleCloudServices';
import { useAudioRecorder } from '@/hooks/useAudioRecorder';
import { useDialogflowAutomation } from '@/hooks/useDialogflowAutomation';
import DebugPanel from '@/components/voice-recorder-phase5/DebugPanel';
import CameraSection from '@/components/voice-recorder-phase5/CameraSection';
import VoiceRecordingSection from '@/components/voice-recorder-phase5/VoiceRecordingSection';
import ResultsDisplay from '@/components/voice-recorder-phase5/ResultsDisplay';
import StatusPanel from '@/components/voice-recorder-phase5/StatusPanel';

interface VoiceRecorderPhase5Props {
  selectedLanguage?: string;
  faceDetectionEnabled?: boolean;
  autoInteractionEnabled?: boolean;
}

const VoiceRecorderPhase5: React.FC<VoiceRecorderPhase5Props> = ({ 
  selectedLanguage = 'en-US',
  faceDetectionEnabled = true,
  autoInteractionEnabled = true
}) => {
  const [greetingMessage, setGreetingMessage] = useState('');
  const [hasGreeted, setHasGreeted] = useState(false);
  const [automationResponse, setAutomationResponse] = useState<any>(null);

  const { speechToText, textToSpeech, playAudio } = useGoogleCloudServices();
  const { processUserQuery } = useDialogflowAutomation();
  
  const { 
    videoRef, 
    isActive: isCameraActive, 
    facesDetected, 
    faceCount,
    isLoading: cameraLoading, 
    startCamera, 
    stopCamera,
    setDetectionCallback
  } = useFaceDetection(faceDetectionEnabled);

  const {
    isRecording,
    audioLevel,
    isProcessing,
    processingTime,
    transcript,
    confidence,
    detectedLanguage,
    startRecording,
    stopRecording,
    resetTranscript
  } = useAudioRecorder(speechToText, {
    autoStop: false,
    silenceDuration: 10000,
    audioThreshold: 0.1
  });

  const greetings = {
    'en-US': 'Hello! Welcome to our hospital. How can I help you today?',
    'hi-IN': 'à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤¹à¤®à¤¾à¤°à¥‡ à¤…à¤¸à¥à¤ªà¤¤à¤¾à¤² à¤®à¥‡à¤‚ à¤†à¤ªà¤•à¤¾ à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤¹à¥ˆà¥¤ à¤†à¤œ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚?',
    'ml-IN': 'à´¨à´®à´¸àµà´•à´¾à´°à´‚! à´žà´™àµà´™à´³àµà´Ÿàµ† à´†à´¶àµà´ªà´¤àµà´°à´¿à´¯à´¿à´²àµ‡à´•àµà´•àµ à´¸àµà´µà´¾à´—à´¤à´‚. à´‡à´¨àµà´¨àµ à´žà´¾àµ» à´¨à´¿à´™àµà´™à´³àµ† à´Žà´™àµà´™à´¨àµ† à´¸à´¹à´¾à´¯à´¿à´•àµà´•à´¾à´‚?',
    'ta-IN': 'à®µà®£à®•à¯à®•à®®à¯! à®Žà®™à¯à®•à®³à¯ à®®à®°à¯à®¤à¯à®¤à¯à®µà®®à®©à¯ˆà®•à¯à®•à¯ à®µà®°à®µà¯‡à®±à¯à®•à®¿à®±à¯‹à®®à¯. à®‡à®©à¯à®±à¯ à®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®Žà®ªà¯à®ªà®Ÿà®¿ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯?'
  };

  // Process transcript through automation system when it's ready
  useEffect(() => {
    const processTranscript = async () => {
      if (transcript && transcript.trim().length > 3 && confidence > 0.5) {
        console.log('ðŸ¤– Processing transcript through automation system:', transcript);
        
        try {
          const sessionId = `phase5_session_${Date.now()}`;
          const result = await processUserQuery(transcript, sessionId, detectedLanguage || selectedLanguage);
          
          console.log('âœ… Automation system response:', result);
          setAutomationResponse(result);
          
          // Play the response if it's successful
          if (result.success && result.responseText) {
            console.log('ðŸ”Š Playing automation response...');
            const ttsResponse = await textToSpeech(result.responseText, detectedLanguage || selectedLanguage);
            if (ttsResponse.success && ttsResponse.audioContent) {
              await playAudio(ttsResponse.audioContent);
            }
          }
        } catch (error) {
          console.error('âŒ Error processing transcript through automation:', error);
          setAutomationResponse({ 
            success: false, 
            responseText: 'I apologize, but I am having trouble processing your request right now.',
            error: error.message 
          });
        }
      }
    };

    if (transcript && !isProcessing) {
      processTranscript();
    }
  }, [transcript, isProcessing, confidence, detectedLanguage, selectedLanguage, processUserQuery, textToSpeech, playAudio]);

  // Set up face detection callback for auto-greeting
  useEffect(() => {
    if (!faceDetectionEnabled || !autoInteractionEnabled) {
      console.log('ðŸš« Face detection or auto interaction disabled in Phase5, skipping callback setup', {
        faceDetectionEnabled,
        autoInteractionEnabled
      });
      
      setHasGreeted(false);
      setGreetingMessage(
        !faceDetectionEnabled ? 'Face detection is disabled' : 
        !autoInteractionEnabled ? 'Auto interaction is disabled' : ''
      );
      return;
    }

    console.log('ðŸ”§ Setting up face detection callback in Phase5...');
    setDetectionCallback((detected: boolean, count: number) => {
      console.log('ðŸ“ž Phase5 received face detection callback:', { 
        detected, 
        count, 
        hasGreeted, 
        selectedLanguage, 
        faceDetectionEnabled,
        autoInteractionEnabled 
      });
      
      if (detected && !hasGreeted && faceDetectionEnabled && autoInteractionEnabled) {
        console.log('ðŸ‘¥ Face detected in Phase5! Triggering auto-greeting...');
        triggerAutoGreeting();
      }
    });
  }, [hasGreeted, setDetectionCallback, selectedLanguage, faceDetectionEnabled, autoInteractionEnabled]);

  const triggerAutoGreeting = async () => {
    if (hasGreeted || !faceDetectionEnabled || !autoInteractionEnabled) {
      console.log('âš ï¸ Greeting blocked:', { 
        hasGreeted, 
        faceDetectionEnabled, 
        autoInteractionEnabled 
      });
      return;
    }
    
    console.log('ðŸ¤– Starting auto-greeting sequence with language:', selectedLanguage);
    setHasGreeted(true);
    
    const currentGreeting = greetings[selectedLanguage] || greetings['en-US'];
    setGreetingMessage(`Auto-greeting (${selectedLanguage}): ${currentGreeting}`);
    
    try {
      console.log('ðŸ”Š Generating TTS for greeting in language:', selectedLanguage);
      const ttsResponse = await textToSpeech(currentGreeting, selectedLanguage);
      if (ttsResponse.success && ttsResponse.audioContent) {
        console.log('ðŸ”Š Playing greeting audio in', selectedLanguage);
        await playAudio(ttsResponse.audioContent);
      }
      
      if (faceDetectionEnabled && autoInteractionEnabled) {
        setTimeout(() => {
          console.log('ðŸŽ¤ Starting recording after greeting...');
          startRecording();
        }, 2000);
      }
    } catch (error) {
      console.error('Error in auto-greeting:', error);
    }
  };

  const resetSession = () => {
    console.log('ðŸ”„ Resetting session...');
    resetTranscript();
    setGreetingMessage('');
    setHasGreeted(false);
    setAutomationResponse(null);
  };

  // Reset greeting state when either setting is disabled
  useEffect(() => {
    if (!faceDetectionEnabled || !autoInteractionEnabled) {
      console.log('ðŸ”„ Settings changed, resetting greeting state...', {
        faceDetectionEnabled,
        autoInteractionEnabled
      });
      setHasGreeted(false);
      setGreetingMessage(
        !faceDetectionEnabled ? 'Face detection is disabled' : 
        !autoInteractionEnabled ? 'Auto interaction is disabled' : ''
      );
    }
  }, [faceDetectionEnabled, autoInteractionEnabled]);

  const handleStartCamera = () => {
    if (faceDetectionEnabled) {
      startCamera();
    } else {
      console.log('ðŸš« Face detection disabled, cannot start camera');
    }
  };

  return (
    <div className="space-y-6">
      <DebugPanel
        isCameraActive={isCameraActive && faceDetectionEnabled}
        facesDetected={faceDetectionEnabled ? facesDetected : false}
        faceCount={faceDetectionEnabled ? faceCount : 0}
        hasGreeted={hasGreeted && faceDetectionEnabled && autoInteractionEnabled}
      />

      <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
        <CameraSection
          videoRef={videoRef}
          isCameraActive={isCameraActive && faceDetectionEnabled}
          facesDetected={faceDetectionEnabled ? facesDetected : false}
          faceCount={faceDetectionEnabled ? faceCount : 0}
          cameraLoading={cameraLoading}
          startCamera={handleStartCamera}
          stopCamera={stopCamera}
        />

        <VoiceRecordingSection
          isRecording={isRecording}
          audioLevel={audioLevel}
          isProcessing={isProcessing}
          startRecording={startRecording}
          stopRecording={stopRecording}
          resetSession={resetSession}
        />
      </div>

      <ResultsDisplay
        greetingMessage={
          !faceDetectionEnabled ? 'Face detection is disabled' :
          !autoInteractionEnabled ? 'Auto interaction is disabled' :
          greetingMessage
        }
        transcript={transcript}
        detectedLanguage={detectedLanguage}
        confidence={confidence}
        processingTime={processingTime}
        faceCount={faceDetectionEnabled ? faceCount : 0}
        automationResponse={automationResponse}
      />

      <StatusPanel
        isCameraActive={isCameraActive && faceDetectionEnabled}
        facesDetected={faceDetectionEnabled ? facesDetected : false}
        hasGreeted={hasGreeted && faceDetectionEnabled && autoInteractionEnabled}
        isRecording={isRecording}
        transcript={transcript}
      />
    </div>
  );
};

export default VoiceRecorderPhase5;
